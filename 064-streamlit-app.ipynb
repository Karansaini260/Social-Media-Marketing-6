{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Overview\n",
    "\n",
    "In this lesson, you'll be building a Streamlit application to generate meme images with the fine-tuned Stable Diffusion model from the previous lesson.  Unlike in previous, in this lesson, you won't be working in this notebook.  All of the tasks (except the first) will done on the ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) command line or in a ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Python file.  We'll use these icons on each task as a reminder.\n",
    "\n",
    "This notebook exists to have these instructions, the videos, and some test code for each task.  This code should be run _after_ you have completed the task.  If it runs successfully, you've probably done the task correctly.  If it doesn't, you'll need to do some more work.  That work needs to be done on the command line or in the Python file.  Don't edit the notebook to get things working!\n",
    "\n",
    "We have a couple of things to import for the testing code.  We're also turning on import reloading, so the notebook stays up to date with the code in the Python file you'll create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload all\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a streamlit app.  In addition to the Python file, we'll need a file to track requirements and a font file.  We also want to track our progress in git.  To keep all of this contained, we'll do this work in a sub-directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.1:** Create a new directory called `meme_app`.  It should be within the directory containing this notebook.  (You could do this through the terminal, but it's easier to use the file browser within JupyterLab.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the file browser within JupyterLab to create a new directory called meme_app\n",
    "# Or you can also use the terminal to create the directory with the command: mkdir meme_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've done so, run the cell below.  It'll change things so that all future commands in this notebook run within this directory.  If it gives you a `FileNotFoundError`, the directory hasn't been created correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('meme_app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "If you restart this notebook, be sure the rerun this cell!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.2:** ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) Configure git by running each of the following commands in the terminal.  You can open a terminal with _File_ > _New_ > _Terminal_.\n",
    "\n",
    "```bash\n",
    "git config --global user.name \"Your Name\"\n",
    "\n",
    "git config --global user.email \"your@email.com\"\n",
    "\n",
    "git config --global init.defaultBranch main\n",
    "```\n",
    "After running these, you should see this information within the output of the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user.name=Karansaini260\n",
      "user.email=kdss3450@gmail.com\n"
     ]
    }
   ],
   "source": [
    "!git config --global --list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.3:** ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) Initialize a git repository in the `meme_app` directory.\n",
    "\n",
    "Don't try to do this from within the notebook.  Instead, within a terminal navigate to the `meme_app` directory with the `cd` command.  The following cell will print the full path to this directory, which you may find helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/meme_app\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(os.path.curdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the appropriate `git` command to initialize a git repository.\n",
    "\n",
    "The following command should output \"No commits yet\", along with other information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.4:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Create a Python file called `app.py` in the `meme_app` directory.  Edit it to import `torch`.  Set a `device` variable to \"cuda\" if a GPU is available or \"cpu\" if one is not.  Set a `dtype` variable to `torch.float16` if a GPU is available or `torch.float32` if one is not.\n",
    "\n",
    "This cell should print out \"cuda with torch.float16\" if everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda with torch.float16\n"
     ]
    }
   ],
   "source": [
    "import app\n",
    "\n",
    "print(f\"{app.device} with {app.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.5:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Create a function `load_model()`.  It should load the Stable Diffusion v1.4 model from Hugging Face and place it on the correct device.  It should return the Stable Diffusion pipeline that gets created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/CompVis/stable-diffusion-v1-4 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7c47e3c9c3d0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: a4f34856-b19a-41c2-8a0e-d2615b39337b)').\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d340e16bdd134884a9e65cd6f26ad2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StableDiffusionPipeline {\n",
      "  \"_class_name\": \"StableDiffusionPipeline\",\n",
      "  \"_diffusers_version\": \"0.32.2\",\n",
      "  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n",
      "  \"feature_extractor\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPImageProcessor\"\n",
      "  ],\n",
      "  \"image_encoder\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"requires_safety_checker\": true,\n",
      "  \"safety_checker\": [\n",
      "    \"stable_diffusion\",\n",
      "    \"StableDiffusionSafetyChecker\"\n",
      "  ],\n",
      "  \"scheduler\": [\n",
      "    \"diffusers\",\n",
      "    \"PNDMScheduler\"\n",
      "  ],\n",
      "  \"text_encoder\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModel\"\n",
      "  ],\n",
      "  \"tokenizer\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"unet\": [\n",
      "    \"diffusers\",\n",
      "    \"UNet2DConditionModel\"\n",
      "  ],\n",
      "  \"vae\": [\n",
      "    \"diffusers\",\n",
      "    \"AutoencoderKL\"\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = app.load_model()\n",
    "\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.6:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Change the code to load the LoRA weights located in `\"rschroll/maya_model_v1_lora\"`. Use that inside of the `load_model` function to load the LoRA weights from Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Changes with respect to the video</b></p>\n",
    "<p>The previous lesson used to push the weigths to HuggingFace. But due to changes to their APIs, we've removed that section. Instead, the weights are provided already.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it by yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/CompVis/stable-diffusion-v1-4 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7c47e217c090>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 9512c1c8-9f6d-493e-96e0-4d355a1750f0)').\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760f24c153db44eea85c584a4a08f155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StableDiffusionPipeline {\n",
      "  \"_class_name\": \"StableDiffusionPipeline\",\n",
      "  \"_diffusers_version\": \"0.32.2\",\n",
      "  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n",
      "  \"feature_extractor\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPImageProcessor\"\n",
      "  ],\n",
      "  \"image_encoder\": [\n",
      "    null,\n",
      "    null\n",
      "  ],\n",
      "  \"requires_safety_checker\": true,\n",
      "  \"safety_checker\": [\n",
      "    \"stable_diffusion\",\n",
      "    \"StableDiffusionSafetyChecker\"\n",
      "  ],\n",
      "  \"scheduler\": [\n",
      "    \"diffusers\",\n",
      "    \"PNDMScheduler\"\n",
      "  ],\n",
      "  \"text_encoder\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModel\"\n",
      "  ],\n",
      "  \"tokenizer\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"unet\": [\n",
      "    \"diffusers\",\n",
      "    \"UNet2DConditionModel\"\n",
      "  ],\n",
      "  \"vae\": [\n",
      "    \"diffusers\",\n",
      "    \"AutoencoderKL\"\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# del pipeline\n",
    "lora_pipeline = app.load_model()\n",
    "\n",
    "print(lora_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great progress so far!  To make sure we don't lose any of it, let's commit what we have to git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.7:** ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) Add `app.py` to the git staging area and then make a commit.\n",
    "\n",
    "The cell below should print out the details of your commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.8:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Create a function `generate_images(prompt, pipeline, n)`.  It should take three arguments:\n",
    "- `prompt`: A image generation prompt, as a string.\n",
    "- `pipeline`: A Stable Diffusion pipeline object.\n",
    "- `n`: The number of images to create, as an integer.\n",
    "\n",
    "It should return a list of PIL Images of length `n`.\n",
    "\n",
    "The following cell will test that this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = app.generate_images(\"My dog Maya generates a Streamlit app.\", lora_pipeline, 1)\n",
    "\n",
    "print(len(images))\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That may not have been a lot of code, but it's a new feature.  That's worth a git commit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.9:** ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) Add and commit the changes to `app.py` to the git repository.\n",
    "\n",
    "You should now see two commits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Meme Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make memorable memes, we want to add some text to these images.  The following function uses the PIL library to superimpose text on an image:\n",
    "\n",
    "```python\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "def add_text_to_image(image, text, text_color=\"white\", outline_color=\"black\",\n",
    "                      font_size=50, border_width=2, font_path=\"arial.ttf\"):\n",
    "    # Initialization\n",
    "    font = ImageFont.truetype(font_path, size=font_size)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "\n",
    "    # Calculate the size of the text\n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "    # Calculate the position at which to draw the text to center it\n",
    "    x = (width - text_width) / 2\n",
    "    y = (height - text_height) / 2\n",
    "\n",
    "    # Draw text\n",
    "    draw.text((x, y), text, font=font, fill=text_color,\n",
    "              stroke_width=border_width, stroke_fill=outline_color)\n",
    "```\n",
    "\n",
    "Note that this code _mutates_ its first argument, and so the function doesn't have a return argument.\n",
    "\n",
    "This function requires a font file to work.  The cell below copies `arial.ttf` into the `meme_app` directory.  Make sure to run it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../arial.ttf ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.10:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Add the `add_text_to_image` function to `app.py`.\n",
    "\n",
    "This cell will try out the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0].copy()  # Avoid mutating the original image\n",
    "app.add_text_to_image(image, \"Data!\")\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.11:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Create a function `generate_memes(prompt, text, pipeline, n)`.  It should take as arguments:\n",
    "- `prompt`: A image generation prompt, as a string.\n",
    "- `text`: The text to superimpose on the images, as a string.\n",
    "- `pipeline`: A Stable Diffusion pipeline object.\n",
    "- `n`: The number of images to create, as an integer.\n",
    "\n",
    "It should generate `n` images from the `prompt`, add the `text` to each one, and return a list of PIL Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = app.generate_memes(\n",
    "    \"My dog Maya has all the memes.\", \"Maya has a meme!\", lora_pipeline, 2\n",
    ")\n",
    "\n",
    "for image in images:\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should be everything we need to create the images.  Let's commit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.12:** ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) Add and commit your changes.  Remember to include `arial.ttf`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Streamlit App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to build a Streamlit app to let people generate meme images of their own.  We'll do this in three steps:\n",
    "- First, we'll set up the inputs.  Users should be able to specify the number images, the prompt, and the text to place over the images.\n",
    "- Second, we'll set up some logic so that we only try to generate images once all of the inputs are ready.  (This is computationally expensive, so we don't want to start this until the user has all the inputs correct.)\n",
    "- Finally, we'll set it to generate the images and display them when ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Task 6.4.13:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Create a Streamlit app that takes the inputs and displays them.  It should look something like this:\n",
    "\n",
    "<img src=\"images/streamlit1.png\" width=\"450px\">\n",
    "\n",
    "Do this by making a function called `main()`.  Inside, construct the Streamlit components you need.  You'll probably find [`st.sidebar`](https://docs.streamlit.io/develop/api-reference/layout/st.sidebar), [`st.number_input()`](https://docs.streamlit.io/develop/api-reference/widgets/st.number_input), and [`st.text_area()`](https://docs.streamlit.io/develop/api-reference/widgets/st.text_area) useful.\n",
    "\n",
    "At the end of `app.py`, add\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "Then you should be able to launch the app from the command line with\n",
    "\n",
    "```bash\n",
    "streamlit run app.py --browser.serverAddress 0.0.0.0 --server.port 9000\n",
    "```\n",
    "\n",
    "Now that the app is running, switch your view to the tab `Streamlit App`:\n",
    "\n",
    "<img src=\"./images/streamlit-view-switch.png\" width=\"600px\">\n",
    "\n",
    "When the Streamlit app is running, the following cell should be able to connect to it.  (If you're having trouble connecting to the proxy, this is a good way of checking that Streamlit is actually running.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "port = 9000\n",
    "resp = requests.get(f\"http://localhost:{port}\", timeout=5)\n",
    "if resp.ok:\n",
    "    print(\"Streamlit server responded\")\n",
    "else:\n",
    "    print(f\"Error connecting to server: {resp.reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can leave the Streamlit server running for the next few steps.  Or you can shut it down and restart it as you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.14:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Add a \"Generate Images\" button to the sidebar.  When clicked, it should display an error if either the prompt or text are empty.  Otherwise, it should display the same message as before.  You'll probably want [`st.button`](https://docs.streamlit.io/develop/api-reference/widgets/st.button), which returns `True` when pressed and `False` otherwise.\n",
    "\n",
    "<img src=\"images/streamlit2.gif\" width=\"450px\">\n",
    "\n",
    "There's no automatic test for this behavior.  It's up to you to judge if it's working!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.15:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Actually generate and display the images when the \"Generate Images\" button is clicked.\n",
    "\n",
    "You'll need to both load the Stable Diffusion model and generate the images, before displaying them with [`st.image`](https://docs.streamlit.io/develop/api-reference/media/st.image).  This will take a long time, so to give the user feedback, add a [spinner](https://docs.streamlit.io/develop/api-reference/status/st.spinner):\n",
    "```python\n",
    "with st.spinner(\"Message\"):\n",
    "    # Long-running code goes here\n",
    "```\n",
    "This will display a spinner, along with your message, while the code is running.  When it completes, the spinner will be replaced by any components created inside of the `with` block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats&mdash;you have a working app!  Let's get it committed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.16:** ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) Commit the changes to git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've probably noticed that the image generation takes a long time.  Part of this is because the app is reloading the Stable Diffusion model every time it's needed.  This doesn't change, so it'd be better to load it once and reuse it.\n",
    "\n",
    "We could do this by making the Stable Diffusion pipeline a global object, loading it at startup.  This would help render more quickly, but would cause the app to start very slowly.  Some hosts consider an app that isn't serving within a second or so of start to be broken, and restart it automatically.  So a slow start time is probably unacceptable.\n",
    "\n",
    "Instead, we can cache the pipeline the first time it's created and reuse it later on.  Luckily for us, Streamlit has the [`@st.cache_resource`](https://docs.streamlit.io/develop/concepts/architecture/caching#stcache_resource) decorator that will do this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.17:** ![PY file](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAcFJREFUOE+l09srBGEYBvDnm5llHWaTtUVs62LLIYfkguSOorgQbsgfQEubw41SkqLkfOMCIUlRUohQIskxh6QosoRYqxY5LLujncnqM5O98N5M3zvP/GbmnW+IIAgC/lFECeib38fKocXD8v6+MOUkI1YfIruVDDi/s6NueBmp0RHon9n6QQLVmGsshr+vikJkwPrxFcq6ppGWEIm1g3Mq3GPORWpUuDLw8PSGk2sbCCFUoLRzyrMeKdcjRq8F4VM8PfEJLNZH5NWPeh2lGzC6mkBUGnCGDhB1FESgdXITI/O7fwK8ewYVDnD2ITHHagvAhlVKgLl3ASu7ZxQQbwyj1oVJDmTrOj09hk8BZ2iTgKr+RSztnIondcE8xk1aBLyOUYDr5ZhaM3waOEOLBHRPbWNgdkcMNJXEIkNT63UebEgR2FCTBBxd3qOmbxE3Vju+B/WXQHx04PTNIH7REuAOv318Yu/sFhrnvjjp71JFttOWIIAEJAKMWuzLNpLwtIEPSzV1ERuUCdfzOrjwBmoPKALupuMwnQa0+XDaJuATtyp7M8WfCZ82OK2DEN4vADAgaiOYoCzx+LuUAa/f4CfwBccEudGSBNSIAAAAAElFTkSuQmCC) Add the [`@st.cache_resource`](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.cache_resource) decorator to the definition of `load_model`.\n",
    "\n",
    "The first time we ask the app to generate some images, it'll take a long time as the model is loaded.  But the following times should be noticeably faster, since the model has been cached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we have hard-coded the LoRA weights into `app.py`.  That works fine for now, but it means that we would need to edit the code to change to a different fine-tuning.\n",
    "\n",
    "Instead, we should load the name of the weights from an environmental variable.  This way, we'll only need to change some configuration settings to switch the fine-tuned model our app uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.4.18:** ![Terminal](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAAAXNSR0IArs4c6QAAAMxJREFUOE+t0jEOREAYBeDHHabXuoEDmOhcQu0GEplEoRSVRriGzBncQCES2qFFMhuyNGywMdUU/zcvmfcrUkqJP46yQMdxHtE0TbHDuq5vYU3T8C60LAtFUfxMP01kjO0gCAJM03R44ADbtkWSJPA8D7quoyxLDMNwDZfPMQwDtm2jqipkWYazpg6J8zzDNE3keY44jhGGIbquu05smgau64IQgr7vVzyO4zXceqSUgnO+At/3oarqeo+iCEIIvNfjrbX5Du2b8wRtsx+xgq/X5YmcbQAAAABJRU5ErkJggg==) Commit these changes to `app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations&mdash;you've built a Streamlit app from scratch! That's it! Go back to the left panel to read the conclusion of this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
